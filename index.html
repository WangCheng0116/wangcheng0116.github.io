<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Cheng Wang's Homepage</title>
  <link rel="icon" type="image/x-icon" href="favicon/favicon.ico">
  
  <meta name="author" content="Cheng Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <style>
    table {
        width: 100%;
        border-spacing: 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
    }
    ul {
        list-style-type: disc;
        padding: 20;
    }
    ul li {
        padding: 2px;
    }

    .tag {
      display: inline-block;
      background-color: #0073e6;
      color: rgb(33, 32, 32);
      padding: 3px 7px;
      border-radius: 15px;
      font-size: 0.8em;
      margin-right: 5px;
    }

    .tag-nlp {
      background-color: #ffc8dd;
    }

    .tag-trust {
      background-color: #cdb4db;
    }

    .tag-reas {
      background-color: #bde0fe;
    }

    .tag-adv {
      background-color: #ff6b6b; /* Red for adversarial attack */
    }

    .tag-inter {
      background-color: #ffafcc; /* Light pink for interpretability */
    }

    .tag-sent {
      background-color: #b8f2e6; /* Light green for sentence embeddings */
    }

    .tag-hallu {
      background-color: #ffbf69; /* Orange for hallucination */
    }

    .tag-vlm {
      background-color: #a0c4ff; /* Blue for vision-language models */
    }

    .tag-alm {
      background-color: #9bf6ff; /* Cyan for audio-language models */
    }

    .conference {
      display: inline-block;
      background-color: #dc3545;
      color: white;
      padding: 4px 10px;
      border-radius: 15px;
      font-size: 0.9em;
      font-weight: bold;
      margin-right: 10px;
    }

    .year-title {
      font-size: 18px;
      font-weight: bold;
      margin-left: 20px;
    }
    
    heading {
      font-size: 24px;
      font-weight: bold;
      display: block;
      margin-bottom: 10px;
    }
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p class="name" style="text-align: center;">
                Cheng Wang
              </p>
              <p>Hi, I am Cheng Wang (çŽ‹ç¨‹). I'm a final-year undergraduate student from <a href="https://www.nus.edu.sg/">National University of Singapore (NUS)</a>. 
                I am broadly interested in <strong>Trustworthy AI</strong>, <strong>LLM Reasoning</strong> and <strong>Agents</strong>.
                I am fortunate to work closely with <a href="https://bhooi.github.io/">Prof. Bryan Hooi</a> and <a href="https://www.chuatatseng.com/">Prof. Tat-Seng Chua</a> from NUS, <a href="https://personal.ntu.edu.sg/tianwei.zhang/">Prof. Tianwei Zhang</a> from NTU, <a href="https://jxhe.github.io/"> Prof. Junxian He</a> from HKUST<a href="https://muhaochen.github.io/">, Prof. Muhao Chen</a> from UC Davis, and <a href="https://web.cs.ucla.edu/~kwchang/">Prof. Kai-Wei Chang</a> from UCLA.
              </p>
              <p>My primary research interests include:</p>
              <ul>
                <li><strong>Trustworthy AI:</strong> Hallucination Detection & Adversarial Robustness.</li>
                <li><strong>AI Reasoning:</strong> Enhancing reasoning abilities of LLMs.</li>
                <li><strong>LLM Applications:</strong> Autonomous agents & RAG systems.</li>
              </ul>
              <p style="text-align:center">
                <a href="mailto:wangcheng@u.nus.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&user=z7idU9gAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/wangchengsg/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/WangCheng0116">Github</a> &nbsp/&nbsp
                <a href="images/wechat.jpg">WeChat</a>
              </p>
              <p style="color: red;">Looking for Fall 2026 PhD opportunities on Trustworthy AI, LLM Reasoning and Agents, feel free to contact!</p>
            </td>
            <td style="padding:2.5%; width:40%; max-width:40%; vertical-align:top;">
              <div style="width: min(230px, 40vw); height: min(230px, 40vw); margin: 0 auto; margin-top: 30px;">
                <a href="images/me.jpg">
                  <img style="width: 100%;
                              height: 100%;
                              object-fit: cover;
                              object-position: center center;
                              border-radius: 50%;
                              display: block;" 
                      alt="profile photo" 
                      src="images/me.jpg" 
                      class="hoverZoomLink">
                </a>
              </div>
            </td>   
          </tr>
        </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="width:100%;vertical-align:middle">
            <heading>ðŸ”¥ News</heading>
          </td>
        </tr>
        </tbody></table>

        <table>
          <tbody>
              <tr>
                  <td>
                      <div>
                          <ul>
                              <li>[2025.08] <strong>Two first-author papers</strong> accepted to EMNLP 2025! One to <strong>Main Track</strong> and one to <strong>Findings</strong>!</li>
                              <li>[2025.06] Our paper <a href="https://arxiv.org/abs/2505.11049">GuardReasoner-VL</a> is accepted to <strong>ICML 2025 R2-FM Workshop</strong>!</li>
                              <li>[2025.04] Our survey on LRMs Safety is on arxiv now, check out the <a href="https://arxiv.org/abs/2504.17704">paper</a> and <a href="https://github.com/WangCheng0116/Awesome-LRMs-Safety">repo</a>!</li>
                              <li>[2025.01] <strong>One first-author paper</strong> is accepted to <strong>NAACL 2025 Main Conference</strong>.</li>
                              <li>[2025.01] I started my internship at Tiktok as an Algorithm Engineer Intern.</li>
                              <li>[2024.11] <strong>One first-author paper</strong> is accepted to <strong>COLING 2025</strong>.</li>
                          </ul>
                      </div>
                  </td>
              </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>ðŸ“‘ Pre-prints & Publications </heading>
              <p>
                <sup>*</sup> denotes equal contribution.
              </p>
            </td>
          </tr>
        </tbody></table>
    
        <!-- <div class="year-title">2025</div> -->

        <table style="width:100%;border:0px;border-spacing:0 5px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rl.png" alt="survey" width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <div style="color: cornflowerblue;">
                <papertitle>Mirage or Method? How Model-Task Alignment Induces Divergent RL Conclusions</papertitle>
              </div>
              Haoze Wu<sup>*</sup>, <strong>Cheng Wang<sup>*</sup></strong>, Wenshuo Zhao, Junxian He
          
              <br>
              <em>Under Review</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2508.21188">Paper</a> / <a href="https://github.com/hkust-nlp/model-task-align-rl">Code</a>

              <br>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/probing.png" alt="survey" width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <div style="color: cornflowerblue;">
                <papertitle>False Sense of Security: Why Probing-based Malicious
                Input Detection Fails to Generalize</papertitle>
              </div>
              <strong>Cheng Wang<sup>*</sup></strong>, Zeming Wei<sup>*</sup>, Qin Liu, Wenxuan Zhou, Muhao Chen

              <br>
              <em>Under Review</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2509.03888">Paper</a> / <a
                href="https://github.com/WangCheng0116/Why-Probe-Fails">Code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/grpo.png" alt="survey" width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <div style="color: cornflowerblue;"><papertitle>Taming Extreme Tokens: Covariance-Aware GRPO with Gaussian-Kernel Advantage Reweighting</papertitle></div>
              <strong>Cheng Wang</strong>, Qin Liu, Wenxuan Zhou, Muhao Chen

              <br>
              <em>Under Review</em>, 2025
              <br>
              <br>
            </td>
          </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/vlm-hallu.png" alt="survey" width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <div style="color: cornflowerblue;">
                  <papertitle>Mitigating Hallucinations in Large Vision-Language Models without Performance Degradation</papertitle>
                </div>
                Xingyu Zhu, Junfeng Fang, Xinfeng Li, <strong>Cheng Wang</strong>, Shuo Wang, Beier Zhu, Xiangnan He
            
                <br>
                <em>Under Review</em>, 2025
                <br>
                <br>
              </td>
            </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MCR.png" alt="survey" width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <div style="color: cornflowerblue;"><span class="conference">EMNLP 2025 Main</span><papertitle>When Audio and Text Disagree: Benchmarking Text Bias in Large Audio-Language Models under Cross-Modal Inconsistencies</papertitle></div>
              <strong>Cheng Wang</strong>, Gelei Deng, Xianglin Yang, Tianwei Zhang          
              <br>
              <a href="https://arxiv.org/abs/2508.15407">Paper</a> / <a href="https://github.com/WangCheng0116/MCR-BENCH">Code</a>
              <br>

            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/guard-vl.png" alt="survey" width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <div style="color: cornflowerblue;"><span class="conference">ICML 2025 R2-FM Workshop</span><papertitle>GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning</papertitle></div>
              Yue Liu, Shengfang Zhai, Mingzhe Du, Yulin Chen, Tri Cao, Hongcheng Gao, <strong>Cheng Wang</strong>, Xinfeng Li, Kun Wang, Junfeng Fang, Jiaheng Zhang, Bryan Hooi
              <br>
              <a href="https://arxiv.org/abs/2505.11049">Paper</a> / <a href="https://github.com/yueliu1999/GuardReasoner-VL/">Code</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/timeline.png" alt="survey" width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <div style="color: cornflowerblue;"><span class="conference">EMNLP 2025 Findings</span><papertitle>Safety in Large Reasoning Models: A Survey</papertitle></div>
              <strong>Cheng Wang<sup>*</sup></strong>, Yue Liu, Baolong Bi, Duzhen Zhang, Zhongzhi Li, Junfeng Fang, Bryan Hooi
              <br>
              <a href="https://arxiv.org/pdf/2504.17704">Paper</a> / <a href="https://github.com/WangCheng0116/Awesome-LRMs-Safety">GitHub</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DIGA.png" alt="DIGA" width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <div style="color: cornflowerblue;"><span class="conference">NAACL 2025 Main</span><papertitle>Tricking Retrievers with Influential Tokens: An Efficient Black-Box Corpus Poisoning Attack</papertitle></div>
              <strong>Cheng Wang</strong>, Yiwei Wang, Yujun Cai, Bryan Hooi
              <br>
              <a href="https://arxiv.org/pdf/2503.21315">Paper</a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/con-recall.jpg" alt="con-recall" width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <div style="color: cornflowerblue;"><span class="conference">COLING 2025</span><papertitle>Con-ReCall: Detecting Pre-training Data in LLMs via Contrastive Decoding</papertitle></div>
              <strong>Cheng Wang</strong>, Yiwei Wang, Bryan Hooi, Yujun Cai, Nanyun Peng, Kai-Wei Chang
              <a href="https://arxiv.org/pdf/2409.03363.pdf">Paper</a> / <a href="https://github.com/WangCheng0116/CON-RECALL">Code</a>
              <br>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="width:100%;vertical-align:middle">
            <heading>ðŸŽ“ Education</heading>
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:15%;vertical-align:middle;">
            <img src="images/NUS.svg" alt="nus" width="120">
          </td>
          <td style="padding:20px;width:85%;vertical-align:middle">
            <strong>National University of Singapore (NUS)</strong>
            <br>
            Period: 2022 - Present
            <br>
            Major: Computer Science & Math
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="width:100%;vertical-align:middle">
            <heading>ðŸ’¼ Professional & Industry Experience</heading>
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:15%;vertical-align:middle; padding-left: 55px;">
            <img src="images/tiktok.svg" alt="tiktok" width="60">
          </td>
          <td style="padding:20px;width:85%;vertical-align:middle">
            <strong>Tiktok</strong> | Singapore
            <br>
            <em>Algorithm Engineer Intern</em>
            <br>
            Period: Jan 2025 - June 2025
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:15%;vertical-align:middle">
            <img src="images/NUS.svg" alt="nus" width="120">
          </td>
          <td style="padding:20px;width:85%;vertical-align:middle">
            <strong>National University of Singapore</strong> | Singapore
            <br>
            <em>Teaching Assistant, Introduction to AI and Machine Learning</em>
            <br>
            Period: Jan 2024 - May 2024
          </td>
        </tr>

      </tbody></table>

      <table>
        <tbody>
            <tr>
                <td>
                  <a href='https://clustrmaps.com/site/1c5sz' title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=tt&d=ij-ZAiC531qZ9RzSIODyxnMEewbok1-0DWh7jQ_I4LI&co=2d78ad&ct=ffffff'/></a>
                </td>
            </tr>
        </tbody>
      </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Last update: Aug 2025
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

  <!-- Definitions for tags -->
  <script>
    // Predefined tags with names and classes
    const tagsMap = {
      'nlp': { name: 'NLP', class: 'tag-nlp' },
      'trust': { name: 'Trustworthy AI', class: 'tag-trust' },
      'reas': { name: 'Large Reasoning Models', class: 'tag-reas' },
      'adv': { name: 'Adversarial Attack', class: 'tag-adv' },
      'inter': { name: 'Interpretability', class: 'tag-inter' },
      'sent': { name: 'Sentence Embeddings', class: 'tag-sent' },
      'hallu': { name: 'Hallucination', class: 'tag-hallu' },
      'vlm': { name: 'Vision-Language Models', class: 'tag-vlm' },
      'alm': { name: 'Audio-Language Models', class: 'tag-alm' }
    };
  
    // Render tags with appropriate CSS classes
    document.querySelectorAll('.tags').forEach(tagDiv => {
      const tagAbbreviations = tagDiv.getAttribute('data-tags').split(',');
      tagAbbreviations.forEach(abbreviation => {
        if (tagsMap[abbreviation]) {
          const tagElement = document.createElement('span');
          tagElement.classList.add('tag', tagsMap[abbreviation].class);
          tagElement.textContent = tagsMap[abbreviation].name;
          tagDiv.appendChild(tagElement);
        }
      });
    });
  </script>
</body>

</html>